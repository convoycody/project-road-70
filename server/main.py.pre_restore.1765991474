from __future__ import annotations

import os
import sqlite3
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict

from fastapi import Body, FastAPI, HTTPException, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles

from server.roadscore import (
    ensure_schema as rs_ensure_schema,
    upsert_segment,
    recompute_scores,
    top_roads,
    road_detail,
    roads_near,
)

ROOT_DIR = Path(__file__).resolve().parent.parent
WEB_DIR = ROOT_DIR / "web"
DB_PATH = Path(os.environ.get("DB_PATH", str(ROOT_DIR / "data.sqlite3")))

API_KEY = (os.environ.get("API_KEY") or "").strip()
ADMIN_USER = (os.environ.get("ADMIN_USER") or "").strip()
ADMIN_PASS = (os.environ.get("ADMIN_PASS") or "").strip()

app = FastAPI(title="Project Road 70", version="0.1.0")







def utc_now() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00", "Z")

def db() -> sqlite3.Connection:
    con = sqlite3.connect(DB_PATH)
    con.row_factory = sqlite3.Row
    con.execute("PRAGMA journal_mode=WAL;")
    con.execute("PRAGMA synchronous=NORMAL;")
    return con

def require_key(req: Request) -> None:
    if not API_KEY:
        return
    k = (req.headers.get("x-api-key") or "").strip()
    if k != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")

def require_admin(req: Request) -> None:
    # If ADMIN_USER/PASS unset, admin is open (use env to lock it down).
    if not ADMIN_USER or not ADMIN_PASS:
        return
    u = (req.headers.get("x-admin-user") or "").strip()
    p = (req.headers.get("x-admin-pass") or "").strip()
    if u != ADMIN_USER or p != ADMIN_PASS:
        raise HTTPException(status_code=401, detail="Admin auth required")

def _f(x):
    if x is None or x == "":
        return None
    try:
        return float(x)
    except Exception:
        return None

def sanitize_lat_lon(d: Dict[str, Any]) -> None:
    lat = _f(d.get("lat"))
    lon = _f(d.get("lon"))
    speed = _f(d.get("speed_mps"))
    notes = []

    if lat is not None and abs(lat) > 90:
        notes.append("sanity:lat_out_of_range")
        lat = None
    if lon is not None and abs(lon) > 180:
        notes.append("sanity:lon_out_of_range")
        lon = None

    # your earlier symptom: lon accidentally became speed-ish
    if lon is not None and speed is not None and abs(lon) <= 60 and abs(speed) <= 60:
        notes.append("sanity:lon_looks_like_speed")

    if notes:
        qn = (d.get("quality_note") or "").strip()
        d["quality_note"] = (qn + (" | " if qn else "") + " ".join(notes)).strip()

    d["lat"] = lat
    d["lon"] = lon

def ensure_tables(con: sqlite3.Connection) -> None:
    con.execute("""
    CREATE TABLE IF NOT EXISTS metric_aggregates (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      received_at TEXT NOT NULL,
      node_id TEXT NOT NULL,
      bucket_start TEXT NOT NULL,
      bucket_seconds INTEGER NOT NULL,
      grid_key TEXT NOT NULL,
      direction TEXT NOT NULL,
      speed_band TEXT NOT NULL,

      road_roughness REAL,
      shock_events INTEGER,
      confidence REAL,
      sample_count INTEGER,

      lat REAL,
      lon REAL,
      speed_mps REAL,
      heading_deg REAL,

      mount_state TEXT DEFAULT '',
      device_posture TEXT DEFAULT '',
      moving INTEGER DEFAULT 0,
      analyzable INTEGER DEFAULT 1,
      points_eligible INTEGER DEFAULT 0,

      road_name TEXT DEFAULT '',
      short_location TEXT DEFAULT '',
      quality_note TEXT DEFAULT ''
    );
    """)
    con.commit()

def table_cols(con: sqlite3.Connection, table: str) -> set[str]:
    rows = con.execute(f"PRAGMA table_info({table})").fetchall()
    return {r["name"] for r in rows}

def named_insert_metric(con: sqlite3.Connection, data: Dict[str, Any]) -> int:
    cols = table_cols(con, "metric_aggregates")
    aliases = {
        "heading": "heading_deg",
        "speed": "speed_mps",
        "lat_deg": "lat",
        "lon_deg": "lon",
    }

    mapped: Dict[str, Any] = {}
    for k, v in (data or {}).items():
        kk = aliases.get(k, k)
        if kk in cols:
            mapped[kk] = v

    d = mapped
    # _ROAD70_DEFAULTS_APPLIED: keep ingest resilient against missing fields
    if d.get('sample_count') in (None, '', 'null'):
        d['sample_count'] = 1
    if d.get('bucket_seconds') in (None, '', 'null'):
        d['bucket_seconds'] = d.get('window_seconds') or 5
    if not d.get('node_id'):
        d['node_id'] = d.get('device_id') or d.get('id') or 'unknown'

    d.setdefault("received_at", utc_now())
    d.setdefault("node_id", "unknown")
    d.setdefault("bucket_start", d["received_at"])
    d.setdefault("bucket_seconds", 5)
    d.setdefault("grid_key", d.get("grid_key") or "seg:unknown")
    d.setdefault("direction", d.get("direction") or "unknown")
    d.setdefault("speed_band", d.get("speed_band") or "unknown")
    d.setdefault("quality_note", d.get("quality_note") or "")

    sanitize_lat_lon(d)

    keys = [k for k in d.keys() if k in cols]
    if not keys:
        raise HTTPException(status_code=400, detail="No writable fields")
    sql = f"INSERT INTO metric_aggregates ({', '.join(keys)}) VALUES ({', '.join('?' for _ in keys)})"
    cur = con.execute(sql, [d[k] for k in keys])
    return int(cur.lastrowid)

@app.on_event("startup")
def _startup() -> None:
    con = db()
    try:
        ensure_tables(con)
    finally:
        con.close()

@app.post("/v1/ingest/aggregates")
async def ingest_aggregates(request: Request, payload: Dict[str, Any] = Body(...)) -> JSONResponse:
    require_key(request)
    con = db()
    try:
        ensure_tables(con)
        row_id = named_insert_metric(con, dict(payload or {}))
        con.commit()
        return JSONResponse({"ok": True, "id": row_id})
    finally:
        con.close()

@app.get("/v1/latest")
async def latest() -> JSONResponse:
    con = db()
    try:
        rows = con.execute("""
          SELECT id, received_at, node_id, lat, lon, speed_mps, heading_deg, confidence,
                 road_name, short_location, quality_note
          FROM metric_aggregates
          ORDER BY id DESC
          LIMIT 200
        """).fetchall()
        return JSONResponse({"rows": [dict(r) for r in rows]})
    finally:
        con.close()

@app.get("/admin", response_class=HTMLResponse)
async def admin_page(request: Request) -> HTMLResponse:
    require_admin(request)
    f = WEB_DIR / "admin.html"
    if not f.exists():
        raise HTTPException(status_code=500, detail="admin.html missing")
    return HTMLResponse(f.read_text())

@app.get("/admin/api/rows")
async def admin_rows(request: Request, limit: int = 150, node: str = "") -> JSONResponse:
    require_admin(request)
    limit = max(10, min(1000, int(limit)))
    node = (node or "").strip()

    con = db()
    try:
        ensure_tables(con)
        if node:
            rows = con.execute("""
              SELECT id, received_at, node_id, lat, lon, speed_mps, heading_deg, confidence,
                     road_name, short_location, quality_note
              FROM metric_aggregates
              WHERE node_id = ?
              ORDER BY id DESC
              LIMIT ?
            """, (node, limit)).fetchall()
        else:
            rows = con.execute("""
              SELECT id, received_at, node_id, lat, lon, speed_mps, heading_deg, confidence,
                     road_name, short_location, quality_note
              FROM metric_aggregates
              ORDER BY id DESC
              LIMIT ?
            """, (limit,)).fetchall()
        return JSONResponse({"rows": [dict(r) for r in rows]})
    finally:
        con.close()

@app.patch("/admin/api/rows/{row_id}")
async def admin_patch_row(request: Request, row_id: int, patch: Dict[str, Any] = Body(...)) -> JSONResponse:
    require_admin(request)
    con = db()
    try:
        ensure_tables(con)
        cols = table_cols(con, "metric_aggregates")
        allowed = {"lat","lon","speed_mps","heading_deg","confidence","road_name","short_location","quality_note"}
        d: Dict[str, Any] = {}
        for k in allowed:
            if k in (patch or {}) and k in cols:
                v = patch.get(k)
                if k in ("lat","lon","speed_mps","heading_deg","confidence"):
                    v = _f(v)
                else:
                    v = (v or "").strip()
                d[k] = v
        if not d:
            raise HTTPException(status_code=400, detail="No editable fields provided")

        tmp = dict(d)
        if "lat" in tmp or "lon" in tmp:
            sanitize_lat_lon(tmp)
            d["lat"] = tmp.get("lat", d.get("lat"))
            d["lon"] = tmp.get("lon", d.get("lon"))
            d["quality_note"] = tmp.get("quality_note", d.get("quality_note",""))

        sets = ", ".join([f"{k} = ?" for k in d.keys()])
        con.execute(f"UPDATE metric_aggregates SET {sets} WHERE id = ?", [d[k] for k in d.keys()] + [int(row_id)])
        con.commit()
        return JSONResponse({"ok": True})
    finally:
        con.close()

@app.delete("/admin/api/rows/{row_id}")
async def admin_delete_row(request: Request, row_id: int) -> JSONResponse:
    require_admin(request)
    con = db()
    try:
        ensure_tables(con)
        con.execute("DELETE FROM metric_aggregates WHERE id = ?", (int(row_id),))
        con.commit()
        return JSONResponse({"ok": True})
    finally:
        con.close()

# IMPORTANT: mount static LAST so it can't swallow /admin or /v1/*
app.mount("/static", StaticFiles(directory=WEB_DIR), name="static")
@app.get("/v1/health")
def health():
    return {"ok": True}

import json, urllib.parse, urllib.request

def _ensure_geocode_tables(con: sqlite3.Connection) -> None:
    con.execute("""
      CREATE TABLE IF NOT EXISTS geocode_cache(
        key TEXT PRIMARY KEY,
        lat REAL,
        lon REAL,
        payload TEXT,
        road_name TEXT,
        hwy_ref TEXT,
        state TEXT,
        county TEXT,
        city TEXT,
        fetched_at INTEGER
      )
    """)
    con.commit()

def _reverse_geocode_cached(con: sqlite3.Connection, lat: float, lon: float) -> dict:
    # round to reduce unique lookups (good cache hit rate)
    key = f"{lat:.5f},{lon:.5f}"
    _ensure_geocode_tables(con)

    row = con.execute("SELECT payload FROM geocode_cache WHERE key=?", (key,)).fetchone()
    if row and row[0]:
        try:
            return json.loads(row[0])
        except Exception:
            pass

    # Nominatim (OpenStreetMap) reverse geocode
    # Keep it gentle: 1 request per new rounded coordinate, 3s timeout.
    url = "https://nominatim.openstreetmap.org/reverse?" + urllib.parse.urlencode({
        "format": "jsonv2",
        "lat": lat,
        "lon": lon,
        "zoom": 18,
        "addressdetails": 1
    })
    req = urllib.request.Request(url, headers={"User-Agent": "project-road-70/0.0.2 (admin@local)"})
    with urllib.request.urlopen(req, timeout=3) as resp:
        payload = resp.read().decode("utf-8", errors="replace")
    j = json.loads(payload)

    addr = (j.get("address") or {})
    road = addr.get("road") or addr.get("pedestrian") or addr.get("path") or addr.get("footway") or addr.get("cycleway")
    hwy = addr.get("highway")  # sometimes present
    # Nominatim sometimes returns "ref" in extra tags; not always present in jsonv2.
    # We'll attempt a few common keys.
    ref = addr.get("ref") or addr.get("route") or None

    state = addr.get("state")
    county = addr.get("county")
    city = addr.get("city") or addr.get("town") or addr.get("village") or addr.get("hamlet")

    con.execute("""
      INSERT INTO geocode_cache(key, lat, lon, payload, road_name, hwy_ref, state, county, city, fetched_at)
      VALUES(?,?,?,?,?,?,?,?,?,strftime('%s','now'))
      ON CONFLICT(key) DO UPDATE SET
        payload=excluded.payload,
        road_name=excluded.road_name,
        hwy_ref=excluded.hwy_ref,
        state=excluded.state,
        county=excluded.county,
        city=excluded.city,
        fetched_at=excluded.fetched_at
    """, (key, lat, lon, payload, road, (ref or hwy), state, county, city))
    con.commit()
    return j

def get_db() -> sqlite3.Connection:
    con = sqlite3.connect("./data.sqlite3", check_same_thread=False)
    con.row_factory = sqlite3.Row
    rs_ensure_schema(con)
    return con

@app.api_route("/admin/api/backfill_geocode", methods=["GET","POST"])
def admin_backfill_geocode(limit: int = 200):
    con = get_db()
    rs_ensure_schema(con)

    # pick rows missing geocode fields but having coords
    rows = con.execute("""
      SELECT id, lat, lon FROM metric_aggregates
      WHERE (road_name IS NULL OR road_name = '')
        AND lat IS NOT NULL AND lon IS NOT NULL
      ORDER BY id DESC
      LIMIT ?
    """, (int(limit),)).fetchall()

    updated = 0
    queued = len(rows)

    for r in rows:
        rid = int(r["id"])
        lat = float(r["lat"])
        lon = float(r["lon"])

        try:
            j = _reverse_geocode_cached(con, lat, lon)
            addr = (j.get("address") or {})
            road = addr.get("road") or addr.get("pedestrian") or addr.get("path") or addr.get("footway") or addr.get("cycleway")
            ref = addr.get("ref") or addr.get("route") or addr.get("highway") or None
            state = addr.get("state")
            county = addr.get("county")
            city = addr.get("city") or addr.get("town") or addr.get("village") or addr.get("hamlet")

            # compute segment_id + upsert segment
            d = {"lat": lat, "lon": lon, "road_name": road, "hwy_ref": ref, "state": state, "county": county, "city": city}
            seg = upsert_segment(con, d)

            con.execute("""
              UPDATE metric_aggregates
              SET road_name=?, hwy_ref=?, state=?, county=?, city=?,
                  geocode_src='nominatim', geocoded_at=strftime('%s','now'),
                  segment_id=?
              WHERE id=?
            """, (road, ref, state, county, city, seg, rid))
            updated += 1
        except Exception:
            # keep going; this is a best-effort batch
            continue

    con.commit()
    return {"ok": True, "updated": updated, "queued": queued}

@app.api_route("/admin/api/recompute_scores", methods=["GET","POST"])
def admin_recompute_scores():
    con = get_db()
    rs_ensure_schema(con)
    r = recompute_scores(con, window_days=7)
    return {"ok": True, **r}

@app.get("/v1/roads/top")
def v1_roads_top(limit: int = 50, state: str | None = None):
    con = get_db()
    items = top_roads(con, limit=int(limit), state=state)
    return {"items": items}

@app.get("/v1/roads/near")
def v1_roads_near(lat: float, lon: float, limit: int = 25):
    con = get_db()
    items = roads_near(con, float(lat), float(lon), int(limit))
    return {"items": items}

@app.get("/v1/road/{segment_id}")
def v1_road(segment_id: str):
    con = get_db()
    return road_detail(con, segment_id)


# Root static mount MUST be last so API POST routes are not shadowed.
app.mount("/", StaticFiles(directory=WEB_DIR, html=True), name="root")




